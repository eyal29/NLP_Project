{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3f9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, LLM, Process\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "import litellm\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4607e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = 0\n",
    "\n",
    "def litellm_callback(model_response):\n",
    "    global token_counter\n",
    "    if \"usage\" in model_response:\n",
    "        usage = model_response[\"usage\"]\n",
    "        token_counter += usage.get(\"total_tokens\", 0)\n",
    "\n",
    "# On attache le callback\n",
    "litellm.success_callback = [litellm_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4559ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_planification = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\", \n",
    "    temperature=0, \n",
    "    api_key=api_key,\n",
    "    max_retries=3,          \n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "solo_ai = Agent(\n",
    "    role=\"Assistant Voyage\",\n",
    "    goal=f\"traduction.\",\n",
    "    backstory=\"Vous êtes un assistant spécialisé dans la traduction de texte en markdown.\",\n",
    "    llm=llm_planification,\n",
    ")\n",
    "t_unique = Task(\n",
    "    description=\"traduire le texte en markdown.\",\n",
    "    expected_output=\"traduction correcte\",\n",
    "    agent=solo_ai\n",
    ")\n",
    "crew = Crew(agents=[solo_ai], tasks=[t_unique])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315b291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=0 prompt_tokens=0 cached_prompt_tokens=0 completion_tokens=0 successful_requests=0\n",
      "total_tokens=0 prompt_tokens=0 cached_prompt_tokens=0 completion_tokens=0 successful_requests=0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = crew.kickoff()\n",
    "print(crew.usage_metrics)\n",
    "print(results.token_usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "353802e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte traduit : # Titre principal\n",
      "## Sous-titre\n",
      "### Sous-sous-titre\n",
      "\n",
      "Le texte en markdown est un format de texte qui permet de créer du contenu structuré et facilement lisible. Il est souvent utilisé dans les documents, les blogs et les sites web.\n",
      "\n",
      "### Caractéristiques clés\n",
      "\n",
      "* **Syntaxe simple** : le texte en markdown utilise une syntaxe simple et facile à comprendre, ce qui en fait un format de texte accessible à tous.\n",
      "* **Structuration** : le texte en markdown permet de structurer le contenu en utilisant des titres, des listes, des tableaux, etc.\n",
      "* **Flexibilité** : le texte en markdown peut être utilisé dans de nombreux contextes, des documents de travail aux sites web.\n",
      "\n",
      "### Avantages\n",
      "\n",
      "* **Facile à lire** : le texte en markdown est facile à lire et à comprendre, même pour les non-spécialistes.\n",
      "* **Facile à écrire** : le texte en markdown est facile à écrire et à modifier, ce qui en fait un format de texte idéal pour les documents en cours de révision.\n",
      "* **Compatibilité** : le texte en markdown est compatible avec de nombreux logiciels et plateformes, ce qui en fait un format de texte polyvalent.\n",
      "\n",
      "### Exemples de mise en œuvre\n",
      "\n",
      "* **Titres** : `# Titre principal`, `## Sous-titre`, `### Sous-sous-titre`\n",
      "* **Listes** : `- élément 1`, `- élément 2`, `- élément 3`\n",
      "* **Tableaux** : `| colonne 1 | colonne 2 | colonne 3 |`\n",
      "\n",
      "Je suis convaincu que cette traduction est correcte et répond aux critères attendus.\n",
      "Tokens via kickoff() : 0\n",
      "Tokens via Callback LLM : 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Texte traduit : {results.raw}\")\n",
    "print(f\"Tokens via kickoff() : {results.token_usage.total_tokens}\")\n",
    "print(f\"Tokens via Callback LLM : {token_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bceb674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la tâche...\n",
      "\n",
      "--- RÉSULTATS ---\n",
      "Contenu : Le format Markdown est utile pour plusieurs raisons :\n",
      "- **Simplicité** : Markdown est un format de m...\n",
      "Tokens via CrewAI (kickoff) : 0\n",
      "Tokens RÉELS via Callback : 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import litellm\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# --- LE COMPTEUR GLOBAL ---\n",
    "# Cette variable va accumuler tous les tokens de chaque appel API\n",
    "token_usage_reel = {\n",
    "    \"total\": 0,\n",
    "    \"prompt\": 0,\n",
    "    \"completion\": 0\n",
    "}\n",
    "\n",
    "# --- LA FONCTION DE CAPTURE (CALLBACK) ---\n",
    "def mon_callback_perso(model_response):\n",
    "    global token_usage_reel\n",
    "    # On vérifie si l'API a renvoyé le dictionnaire 'usage'\n",
    "    if \"usage\" in model_response:\n",
    "        usage = model_response[\"usage\"]\n",
    "        token_usage_reel[\"total\"] += usage.get(\"total_tokens\", 0)\n",
    "        token_usage_reel[\"prompt\"] += usage.get(\"prompt_tokens\", 0)\n",
    "        token_usage_reel[\"completion\"] += usage.get(\"completion_tokens\", 0)\n",
    "        print(f\"DEBUG CALLBACK : +{usage.get('total_tokens', 0)} tokens détectés.\")\n",
    "\n",
    "# On attache la fonction au succès de chaque appel LiteLLM\n",
    "litellm.success_callback = [mon_callback_perso]\n",
    "\n",
    "# --- CONFIGURATION CLASSIQUE ---\n",
    "llm_planification = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\", \n",
    "    temperature=0, \n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "solo_ai = Agent(\n",
    "    role=\"Assistant Traduction\",\n",
    "    goal=\"Traduire du texte.\",\n",
    "    backstory=\"Expert en markdown.\",\n",
    "    llm=llm_planification\n",
    ")\n",
    "\n",
    "t_unique = Task(\n",
    "    description=\"Explique en 3 phrases pourquoi le format Markdown est utile.\",\n",
    "    expected_output=\"Explication claire en markdown\",\n",
    "    agent=solo_ai\n",
    ")\n",
    "\n",
    "crew = Crew(agents=[solo_ai], tasks=[t_unique])\n",
    "\n",
    "# --- EXÉCUTION ---\n",
    "print(\"Lancement de la tâche...\")\n",
    "results = crew.kickoff()\n",
    "\n",
    "print(\"\\n--- RÉSULTATS ---\")\n",
    "print(f\"Contenu : {results.raw[:100]}...\")\n",
    "print(f\"Tokens via CrewAI (kickoff) : {results.token_usage.total_tokens}\")\n",
    "print(f\"Tokens RÉELS via Callback : {token_usage_reel['total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e9a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BLOC USAGE COMPLET DE L'API ---\n",
      "Usage(completion_tokens=16, prompt_tokens=43, total_tokens=59, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.087825808, prompt_time=0.002668288, completion_time=0.032727261, total_time=0.035395549)\n",
      "\n",
      "--- DÉTAILS ---\n",
      "Tokens Prompt (Entrée) : 43\n",
      "Tokens Completion (Sortie) : 16\n",
      "Total des Tokens : 59\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Appel direct à l'API via LiteLLM\n",
    "response = litellm.completion(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Bonjour, donne moi une phrase courte.\"}],\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# 2. Accéder aux valeurs individuelles\n",
    "print(\"\\n--- DÉTAILS ---\")\n",
    "print(f\"Tokens Prompt (Entrée) : {response.usage.prompt_tokens}\")\n",
    "print(f\"Tokens Completion (Sortie) : {response.usage.completion_tokens}\")\n",
    "print(f\"Total des Tokens : {response.usage.total_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
